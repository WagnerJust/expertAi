#!/usr/bin/env python3
"""
Mock LLM Service for testing RAG pipeline
"""
from flask import Flask, request, jsonify
import json
import time

app = Flask(__name__)

@app.route('/api/generate', methods=['POST'])
def generate():
    """Mock Ollama API endpoint"""
    data = request.json
    prompt = data.get('prompt', '')
    model = data.get('model', 'mock')
    
    # Mock response based on prompt content
    if 'artificial intelligence' in prompt.lower():
        response_text = "Artificial intelligence (AI) is a branch of computer science that aims to create intelligent machines that can perform tasks typically requiring human intelligence, such as learning, reasoning, and problem-solving."
    elif 'hello' in prompt.lower():
        response_text = "Hello! I'm a mock AI assistant ready to help you with your questions."
    elif 'context' in prompt.lower() and 'question' in prompt.lower():
        # This looks like a RAG prompt
        response_text = "Based on the provided context, I can help answer your question. However, this is a mock response for testing purposes."
    else:
        response_text = f"This is a mock response to your prompt. In a real system, this would be generated by the {model} model."
    
    # Simulate some processing time
    time.sleep(1)
    
    return jsonify({
        "model": model,
        "created_at": "2025-06-08T00:00:00Z",
        "response": response_text,
        "done": True,
        "done_reason": "stop"
    })

@app.route('/api/version', methods=['GET'])
def version():
    """Mock version endpoint"""
    return jsonify({"version": "mock-1.0.0"})

if __name__ == '__main__':
    print("ðŸš€ Starting Mock LLM Service on port 11435")
    print("This service will respond to Ollama-compatible API calls")
    app.run(host='0.0.0.0', port=11435, debug=True)
